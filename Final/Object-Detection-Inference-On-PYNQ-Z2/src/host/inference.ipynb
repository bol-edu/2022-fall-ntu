{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e72f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘output’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c390dccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import xml.etree.ElementTree as ET\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "from driver import io_shape_dict\n",
    "from driver_base import FINNExampleOverlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a051f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download and unzip\n",
    "#! pip3 install gdown\n",
    "#! gdown https://drive.google.com/uc?id=1ZE0XgaVlYMl9Y7QP2-ggyGICxL0T5p-T\n",
    "#! unzip voc2007.zip\n",
    "#! unzip pynq_deployment_0nptxqpx-20221227T055358Z-001.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2889f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(boxes_preds, boxes_labels):\n",
    "    #print(boxes_preds, boxes_labels)\n",
    "    box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
    "    box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
    "    box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
    "    box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
    "    box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
    "    box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
    "    box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
    "    box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
    "\n",
    "    x1 = np.maximum(box1_x1, box2_x1)\n",
    "    y1 = np.maximum(box1_y1, box2_y1)\n",
    "    x2 = np.minimum(box1_x2, box2_x2)\n",
    "    y2 = np.minimum(box1_y2, box2_y2)\n",
    "\n",
    "    intersection = (x2 - x1).clip(0) * (y2 - y1).clip(0)\n",
    "\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "    \n",
    "    return intersection / (box1_area + box2_area - intersection + 1e-6)\n",
    "\n",
    "def non_max_suppression(bboxes, iou_threshold, threshold):\n",
    "\n",
    "    bboxes = [box for box in bboxes if box[1] > threshold]\n",
    "    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n",
    "    bboxes_after_nms = []\n",
    "\n",
    "    while bboxes:\n",
    "        #print(bboxes)\n",
    "        chosen_box = bboxes.pop(0)\n",
    "        bboxes = [box for box in bboxes if box[0] != chosen_box[0] or intersection_over_union(np.array(chosen_box[2:]), np.array(box[2:])) < iou_threshold ]\n",
    "        bboxes_after_nms.append(chosen_box)\n",
    "        \n",
    "    return bboxes_after_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57afde57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cellboxes(predictions, S=3, C=20):\n",
    "\n",
    "    batch_size = predictions.shape[0]\n",
    "    predictions = predictions.reshape(batch_size, S, S, C + 10)\n",
    "    bboxes1 = predictions[..., C + 1:C + 5]\n",
    "    bboxes2 = predictions[..., C + 6:C + 10]\n",
    "    scores = np.concatenate(\n",
    "        (np.expand_dims(predictions[..., C], 0), np.expand_dims(predictions[..., C + 5],0)), axis=0\n",
    "    )\n",
    "    best_box = np.expand_dims(scores.argmax(0),-1)\n",
    "    best_boxes = bboxes1 * (1 - best_box) + best_box * bboxes2\n",
    "    cell_indices = np.expand_dims(np.expand_dims(np.arange(S).reshape(1,-1).repeat(S, axis=0), 0), -1)\n",
    "    x = 1 / S * (best_boxes[..., :1] + cell_indices)\n",
    "    y = 1 / S * (best_boxes[..., 1:2] + np.transpose(cell_indices ,(0, 2, 1, 3)))\n",
    "    w_y = 1 / S * best_boxes[..., 2:4]\n",
    "    converted_bboxes = np.concatenate((x, y, w_y), axis=-1)\n",
    "    predicted_class = np.expand_dims(predictions[..., :C].argmax(-1), -1)\n",
    "    best_confidence = np.expand_dims(np.maximum(predictions[..., C], predictions[..., C + 5]), -1)\n",
    "    converted_preds = np.concatenate((predicted_class, best_confidence, converted_bboxes), axis=-1)\n",
    "    \n",
    "    return converted_preds\n",
    "\n",
    "\n",
    "def cellboxes_to_boxes(out, S=3):\n",
    "    converted_pred = convert_cellboxes(out).reshape(out.shape[0], S * S, -1)\n",
    "    #converted_pred[..., 0] = converted_pred[..., 0].long()\n",
    "    all_bboxes = []\n",
    "\n",
    "    for ex_idx in range(out.shape[0]):\n",
    "        bboxes = []\n",
    "\n",
    "        for bbox_idx in range(S * S):\n",
    "            bboxes.append([x.item() for x in converted_pred[ex_idx, bbox_idx, :]])\n",
    "        all_bboxes.append(bboxes)\n",
    "\n",
    "    return all_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebc4265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blender(predbboxes, gtbboxes, filenames, widths, heights):\n",
    "    #print(predbboxes, gtbboxes)\n",
    "    label_dictionary = {0:'aeroplane', 1:'bicycle', 2:'bird', 3:'boat', 4:'bottle', 5:'bus', 6:'car', 7:'cat', 8:'chair', 9:'cow', 10:'diningtable', 11:'dog',\n",
    "        12:'horse', 13:'motorbike', 14:'person', 15:'pottedplant', 16:'sheep', 17:'sofa', 18:'train', 19:'tvmonitor'}\n",
    "\n",
    "    img_w = widths\n",
    "    img_h = heights\n",
    "    cv2image = cv2.imread(os.path.join(filenames))\n",
    "    #print(cv2image)\n",
    "    # blender gt\n",
    "    for n in range(len(gtbboxes)):\n",
    "        bbox_width = float(gtbboxes[n][4]) * img_w\n",
    "        bbox_height = float(gtbboxes[n][5]) * img_h\n",
    "        center_x = float(gtbboxes[n][2]) * img_w\n",
    "        center_y = float(gtbboxes[n][3]) * img_h\n",
    "        min_x, min_y = center_x - (bbox_width / 2), center_y - (bbox_height / 2)\n",
    "        max_x, max_y = center_x + (bbox_width / 2), center_y + (bbox_height / 2)\n",
    "        #print(min_x,min_y,max_x,max_y)\n",
    "        cv2.putText(cv2image, label_dictionary[int(gtbboxes[n][0])], (int(min_x), int(min_y-6)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 1, cv2.LINE_AA)\n",
    "        cv2.rectangle(cv2image, (int(min_x),int(min_y)), (int(max_x),int(max_y)), (255,255,0), 2)\n",
    "    \n",
    "    for n in range(len(predbboxes)):\n",
    "        # blender pred\n",
    "        bbox_width = float(predbboxes[n][4]) * img_w\n",
    "        bbox_height = float(predbboxes[n][5]) * img_h\n",
    "        center_x = float(predbboxes[n][2]) * img_w\n",
    "        center_y = float(predbboxes[n][3]) * img_h\n",
    "        min_x, min_y = center_x - (bbox_width / 2), center_y - (bbox_height / 2)\n",
    "        max_x, max_y = center_x + (bbox_width / 2), center_y + (bbox_height / 2)\n",
    "        #print(min_x,min_y,max_x,max_y)\n",
    "        cv2.putText(cv2image, label_dictionary[int(predbboxes[n][0])], (int(min_x), int(min_y-6)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.rectangle(cv2image, (int(min_x),int(min_y)), (int(max_x),int(max_y)), (255,0,255), 2)\n",
    "        #print(label_dictionary[int(predbboxes[n][0])])\n",
    "        \n",
    "    cv2.imwrite(f'./output/{filenames}', cv2image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64c36e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(\n",
    "    pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"midpoint\", num_classes=20\n",
    "):\n",
    "\n",
    "    # list storing all AP for respective classes\n",
    "    average_precisions = []\n",
    "\n",
    "    # used for numerical stability later on\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        detections = []\n",
    "        ground_truths = []\n",
    "        for detection in pred_boxes:\n",
    "            if detection[1] == c:\n",
    "                detections.append(detection)\n",
    "\n",
    "        for true_box in true_boxes:\n",
    "            if true_box[1] == c:\n",
    "                ground_truths.append(true_box)\n",
    "\n",
    "        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n",
    "        \n",
    "        for key, val in amount_bboxes.items():\n",
    "            amount_bboxes[key] = np.zeros(val)\n",
    "\n",
    "        detections.sort(key=lambda x: x[2], reverse=True)\n",
    "        TP = np.zeros((len(detections)))\n",
    "        FP = np.zeros((len(detections)))\n",
    "        total_true_bboxes = len(ground_truths)\n",
    "        \n",
    "        if total_true_bboxes == 0:\n",
    "            continue\n",
    "\n",
    "        for detection_idx, detection in enumerate(detections):\n",
    "    \n",
    "            ground_truth_img = [bbox for bbox in ground_truths if bbox[0] == detection[0]]\n",
    "            \n",
    "            num_gts = len(ground_truth_img)\n",
    "            best_iou = 0\n",
    "\n",
    "            for idx, gt in enumerate(ground_truth_img):\n",
    "                \n",
    "                iou = intersection_over_union(np.array((detection[3:])), np.array(gt[3:]))\n",
    "\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = idx\n",
    "            \n",
    "            if best_iou > iou_threshold:\n",
    "                # only detect ground truth detection once\n",
    "                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n",
    "                    # true positive and add this bounding box to seen\n",
    "                    TP[detection_idx] = 1\n",
    "                    amount_bboxes[detection[0]][best_gt_idx] = 1\n",
    "                else:\n",
    "                    FP[detection_idx] = 1\n",
    "\n",
    "            # if IOU is lower then the detection is a false positive\n",
    "            else:\n",
    "                FP[detection_idx] = 1\n",
    "\n",
    "        TP_cumsum = np.cumsum(TP, axis=0)\n",
    "        FP_cumsum = np.cumsum(FP, axis=0)\n",
    "        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n",
    "        precisions = np.divide(TP_cumsum, (TP_cumsum + FP_cumsum + epsilon))\n",
    "        precisions = np.concatenate((np.array([1]), precisions))\n",
    "        recalls = np.concatenate((np.array([0]), recalls))\n",
    "        # torch.trapz for numerical integration\n",
    "        average_precisions.append(np.trapz(precisions, recalls))\n",
    "    #print(\"ap \", average_precisions)\n",
    "    return sum(average_precisions) / len(average_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c4c150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 3\n",
    "B = 2\n",
    "C = 20\n",
    "iou_threshold = 0.5\n",
    "threshold = 0.4\n",
    "\n",
    "#test_file = []\n",
    "'''for line in f:\n",
    "    test_file.append(line.replace('\\n', ''))\n",
    "f.close()'''\n",
    "test_files = []\n",
    "test_files.append('./000355')\n",
    "\n",
    "label_dictionary = {'aeroplane':0, 'bicycle':1, 'bird':2, 'boat':3, 'bottle':4, 'bus':5, 'car':6, 'cat':7, 'chair':8, 'cow':9, 'diningtable':10, 'dog':11,\n",
    "                    'horse':12, 'motorbike':13, 'person':14, 'pottedplant':15, 'sheep':16, 'sofa':17, 'train':18, 'tvmonitor':19}\n",
    "all_pred_boxes = []\n",
    "all_true_boxes = []\n",
    "idx = 0\n",
    "\n",
    "driver = FINNExampleOverlay(\n",
    "    bitfile_name=\"./bitfile/finn-accel.bit\",\n",
    "    platform=\"zynq-iodma\",\n",
    "    io_shape_dict=io_shape_dict,\n",
    "    batch_size=1,\n",
    "    runtime_weight_dir=\"runtime_weights/\",\n",
    ")\n",
    "for number, test_file in enumerate(test_files):\n",
    "    \n",
    "    filexml = str(test_file) + \".xml\"\n",
    "        \n",
    "    boxes = []\n",
    "    tree = ET.parse(filexml)\n",
    "    root = tree.getroot()\n",
    "    filename = root.find('filename').text\n",
    "    #print(filename)\n",
    "    \n",
    "    img_org = cv2.imread(filename)\n",
    "    img = img_org.copy()  \n",
    "    h, w, _ = img_org.shape\n",
    "    #img = img.astype(np.uint8)\n",
    "    img = cv2.resize(img, (48, 48), interpolation=cv2.INTER_AREA)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #driver_in = np.expand_dims(img, 0)\n",
    "    #print(driver_in.shape)\n",
    "    \n",
    "    img_width = int(root.find('size').find('width').text)\n",
    "    img_height = int(root.find('size').find('height').text)\n",
    "    \n",
    "    for member in root.findall('object'):\n",
    "\n",
    "        name = member.find('name').text\n",
    "        label = label_dictionary[name]\n",
    "\n",
    "        xmin = int(member.find('bndbox').find('xmin').text)\n",
    "        xmax = int(member.find('bndbox').find('xmax').text)\n",
    "        \n",
    "        ymin = int(member.find('bndbox').find('ymin').text)\n",
    "        ymax = int(member.find('bndbox').find('ymax').text)\n",
    "        \n",
    "        centerx = ((xmax + xmin) / 2) / img_width\n",
    "        centery = ((ymax + ymin) / 2) / img_height\n",
    "        boxwidth = (xmax - xmin) / img_width\n",
    "        boxheight = (ymax - ymin) / img_height\n",
    "\n",
    "        boxes.append([label, centerx, centery, boxwidth, boxheight])\n",
    "\n",
    "    boxes = np.array(boxes)\n",
    "    \n",
    "    label_matrix = np.zeros((S, S, C + 5 * B))\n",
    "\n",
    "    for box in boxes:\n",
    "        class_label, x, y, width, height = box.tolist()\n",
    "        class_label = int(class_label)\n",
    "\n",
    "        i, j = int(S * y), int(S * x)\n",
    "        x_cell, y_cell = S * x - j, S * y - i\n",
    "\n",
    "        width_cell, height_cell = (width * S, height * S)\n",
    "\n",
    "        if label_matrix[i, j, C] == 0:\n",
    "            label_matrix[i, j, C] = 1\n",
    "\n",
    "            box_coordinates = np.array([x_cell, y_cell, width_cell, height_cell])\n",
    "\n",
    "            label_matrix[i, j, 21:25] = box_coordinates\n",
    "\n",
    "            label_matrix[i, j, class_label] = 1\n",
    "    label_matrix = np.expand_dims(label_matrix, 0)\n",
    "    \n",
    "\n",
    "    driver_in = np.expand_dims(img, 0)\n",
    "    output = driver.execute(driver_in)\n",
    "    #print(output)\n",
    "    output =0.0034094545990228653*output+0.2782003879547119\n",
    "    predictions = output.reshape(1, 3, 3, 30)\n",
    "    \n",
    "    true_bboxes = cellboxes_to_boxes(label_matrix)\n",
    "    pred_bboxes = cellboxes_to_boxes(predictions)\n",
    "    \n",
    "    nms_pred_bboxes = non_max_suppression(pred_bboxes[0], iou_threshold=iou_threshold, threshold=threshold)\n",
    "    gtbboxes = [box for box in true_bboxes[0] if box[1] > threshold]\n",
    "    \n",
    "    blender(nms_pred_bboxes, gtbboxes, filename, img_width, img_height)\n",
    "    \n",
    "    for nms_box in nms_pred_bboxes:\n",
    "        all_pred_boxes.append([idx] + nms_box)\n",
    "\n",
    "    for box in true_bboxes[0]:\n",
    "        if box[1] > threshold:\n",
    "            all_true_boxes.append([idx] + box)\n",
    "\n",
    "    idx += 1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c508811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d2bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
